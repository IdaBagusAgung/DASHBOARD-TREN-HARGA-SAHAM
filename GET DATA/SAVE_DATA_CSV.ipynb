{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7df4823",
   "metadata": {},
   "source": [
    "# SAVE DATA CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36122a50",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "7 columns passed, passed data had 3 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\proda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\proda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[1;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns passed, passed data had \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    989\u001b[0m     )\n\u001b[0;32m    990\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 7 columns passed, passed data had 3 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m cursor\u001b[38;5;241m.\u001b[39mexecute(sql)\n\u001b[0;32m     28\u001b[0m data \u001b[38;5;241m=\u001b[39m cursor\u001b[38;5;241m.\u001b[39mfetchall()\n\u001b[1;32m---> 29\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOpen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHigh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVolume\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTicker\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatetime\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\proda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:851\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    849\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m         columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[1;32m--> 851\u001b[0m     arrays, columns, index \u001b[38;5;241m=\u001b[39m \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    852\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[0;32m    853\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[0;32m    854\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    855\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    857\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    859\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[0;32m    860\u001b[0m         arrays,\n\u001b[0;32m    861\u001b[0m         columns,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    864\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    865\u001b[0m     )\n\u001b[0;32m    866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\proda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    518\u001b[0m     columns \u001b[38;5;241m=\u001b[39m ensure_index(data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_fields)\n\u001b[1;32m--> 520\u001b[0m arrays, columns \u001b[38;5;241m=\u001b[39m \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m columns \u001b[38;5;241m=\u001b[39m ensure_index(columns)\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\proda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    842\u001b[0m     data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m    843\u001b[0m     arr \u001b[38;5;241m=\u001b[39m _list_to_arrays(data)\n\u001b[1;32m--> 845\u001b[0m content, columns \u001b[38;5;241m=\u001b[39m \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "File \u001b[1;32mc:\\Users\\proda\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    939\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[1;32m--> 942\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject_:\n\u001b[0;32m    945\u001b[0m     contents \u001b[38;5;241m=\u001b[39m convert_object_array(contents, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mValueError\u001b[0m: 7 columns passed, passed data had 3 columns"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "\n",
    "# MySQL connection setup\n",
    "connection = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='',\n",
    "    database='harga_saham'\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# List of tickers\n",
    "tickers = ['ACES.JK', 'ADMR.JK', 'ADRO.JK', 'AKRA.JK', 'AMMN.JK', 'AMRT.JK', 'ANTM.JK',\n",
    "    'ARTO.JK', 'ASII.JK', 'BBCA.JK', 'BBNI.JK', 'BBRI.JK', 'BMRI.JK', 'BRIS.JK',\n",
    "    'BRPT.JK', 'BUKA.JK', 'CPIN.JK', 'EMTK.JK', 'ESSA.JK', 'EXCL.JK', 'GOTO.JK',\n",
    "    'GGRM.JK', 'HRUM.JK', 'ICBP.JK', 'INCO.JK', 'INDF.JK', 'INKP.JK', 'INTP.JK',\n",
    "    'ITMG.JK', 'JPFA.JK', 'JSMR.JK', 'KLBF.JK', 'MAPI.JK', 'MBMA.JK', 'MDKA.JK',\n",
    "    'MEDC.JK', 'PGAS.JK', 'PGEO.JK', 'PTBA.JK', 'SIDO.JK', 'SMGR.JK', 'SRTG.JK',\n",
    "    'TLKM.JK', 'TPIA.JK', 'UNTR.JK', 'UNVR.JK']\n",
    "\n",
    "\n",
    "# Retrieve data from MySQL\n",
    "retrieved_data = {}\n",
    "for ticker in tickers:\n",
    "    sql = f\"SELECT * FROM data_saham_max_all_mei WHERE Ticker = '{ticker}'\"\n",
    "    cursor.execute(sql)\n",
    "    data = cursor.fetchall()\n",
    "    df = pd.DataFrame(data, columns=['Datetime', 'Open', 'High', 'Low', 'Close', 'Volume', 'Ticker'])\n",
    "    df.set_index('Datetime', inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    retrieved_data[ticker] = df\n",
    "    print(f\"Data for {ticker} has been successfully retrieved from MySQL.\")\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "print(\"Data retrieval process completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ecf5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder 'BACKUP_DATASET' telah dibuat.\n",
      "Koneksi ke MySQL berhasil.\n",
      "Terjadi error saat memproses ticker ACES.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker ADMR.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker ADRO.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker AKRA.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker AMMN.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker AMRT.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker ANTM.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker ARTO.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker ASII.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker BBCA.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker BBNI.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker BBRI.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker BMRI.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker BRIS.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker BRPT.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker BUKA.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker CPIN.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker EMTK.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker ESSA.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker EXCL.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker GOTO.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker GGRM.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker HRUM.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker ICBP.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker INCO.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker INDF.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker INKP.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker INTP.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker ITMG.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker JPFA.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker JSMR.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker KLBF.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker MAPI.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker MBMA.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker MDKA.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker MEDC.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker PGAS.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker PGEO.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker PTBA.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker SIDO.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker SMGR.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker SRTG.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker TLKM.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker TPIA.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker UNTR.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "Terjadi error saat memproses ticker UNVR.JK: (1054, \"Unknown column 'Datetime' in 'field list'\")\n",
      "\n",
      "Koneksi ke MySQL telah ditutup.\n",
      "Proses pengambilan dan backup data selesai.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import os\n",
    "\n",
    "# --- Persiapan ---\n",
    "# 1. Pastikan library openpyxl sudah terinstall untuk menyimpan file Excel\n",
    "#    Jalankan di terminal/CMD: pip install openpyxl\n",
    "\n",
    "# 2. Buat folder untuk menyimpan backup jika belum ada\n",
    "output_folder = 'BACKUP_DATASET'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    print(f\"Folder '{output_folder}' telah dibuat.\")\n",
    "\n",
    "# --- MySQL Connection Setup ---\n",
    "try:\n",
    "    connection = pymysql.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='',\n",
    "        database='harga_saham'\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    print(\"Koneksi ke MySQL berhasil.\")\n",
    "except pymysql.Error as e:\n",
    "    print(f\"Error saat menghubungkan ke MySQL: {e}\")\n",
    "    exit() # Keluar dari script jika koneksi gagal\n",
    "\n",
    "# --- List of Tickers ---\n",
    "tickers = ['ACES.JK', 'ADMR.JK', 'ADRO.JK', 'AKRA.JK', 'AMMN.JK', 'AMRT.JK', 'ANTM.JK',\n",
    "    'ARTO.JK', 'ASII.JK', 'BBCA.JK', 'BBNI.JK', 'BBRI.JK', 'BMRI.JK', 'BRIS.JK',\n",
    "    'BRPT.JK', 'BUKA.JK', 'CPIN.JK', 'EMTK.JK', 'ESSA.JK', 'EXCL.JK', 'GOTO.JK',\n",
    "    'GGRM.JK', 'HRUM.JK', 'ICBP.JK', 'INCO.JK', 'INDF.JK', 'INKP.JK', 'INTP.JK',\n",
    "    'ITMG.JK', 'JPFA.JK', 'JSMR.JK', 'KLBF.JK', 'MAPI.JK', 'MBMA.JK', 'MDKA.JK',\n",
    "    'MEDC.JK', 'PGAS.JK', 'PGEO.JK', 'PTBA.JK', 'SIDO.JK', 'SMGR.JK', 'SRTG.JK',\n",
    "    'TLKM.JK', 'TPIA.JK', 'UNTR.JK', 'UNVR.JK']\n",
    "\n",
    "# --- Proses Pengambilan dan Penyimpanan Data ---\n",
    "retrieved_data = {}\n",
    "column_names = ['Datetime', 'Open', 'High', 'Low', 'Close', 'Volume', 'Ticker']\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # PERBAIKAN: Sebutkan nama kolom secara eksplisit dalam query SQL\n",
    "        # Ini adalah praktik terbaik untuk menghindari error jika urutan kolom di DB berubah\n",
    "        sql = f\"SELECT Datetime, Open, High, Low, Close, Volume, Ticker FROM data_saham_max_all_mei WHERE Ticker = '{ticker}'\"\n",
    "        \n",
    "        cursor.execute(sql)\n",
    "        data = cursor.fetchall()\n",
    "\n",
    "        if not data:\n",
    "            print(f\"Tidak ada data ditemukan untuk {ticker}. Melewati...\")\n",
    "            continue\n",
    "\n",
    "        # Membuat DataFrame dengan nama kolom yang sudah pasti benar\n",
    "        df = pd.DataFrame(data, columns=column_names)\n",
    "        \n",
    "        # Konversi dan set index\n",
    "        df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "        df.set_index('Datetime', inplace=True)\n",
    "        \n",
    "        retrieved_data[ticker] = df\n",
    "        print(f\"Data untuk {ticker} berhasil diambil dari MySQL.\")\n",
    "\n",
    "        # --- PENAMBAHAN: Menyimpan data ke file CSV dan Excel ---\n",
    "        # Membuat nama file yang aman (mengganti '.' dengan '_')\n",
    "        safe_ticker_name = ticker.replace('.', '_')\n",
    "        \n",
    "        # Path untuk file CSV dan Excel\n",
    "        csv_path = os.path.join(output_folder, f'{safe_ticker_name}.csv')\n",
    "        excel_path = os.path.join(output_folder, f'{safe_ticker_name}.xlsx')\n",
    "\n",
    "        # Menyimpan ke file\n",
    "        df.to_csv(csv_path)\n",
    "        df.to_excel(excel_path)\n",
    "        \n",
    "        print(f\" -> Data {ticker} telah disimpan ke {csv_path} dan {excel_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Terjadi error saat memproses ticker {ticker}: {e}\")\n",
    "\n",
    "\n",
    "# --- Menutup Koneksi ---\n",
    "cursor.close()\n",
    "connection.close()\n",
    "print(\"\\nKoneksi ke MySQL telah ditutup.\")\n",
    "print(\"Proses pengambilan dan backup data selesai.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b293e289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_json(tickers, json_folder='DATA_JSON'):\n",
    "    \"\"\"\n",
    "    Memuat data historis saham dari file-file JSON.\n",
    "\n",
    "    Args:\n",
    "        tickers (list): Daftar ticker saham yang akan dimuat.\n",
    "        json_folder (str): Nama folder tempat file JSON disimpan.\n",
    "\n",
    "    Returns:\n",
    "        dict: Sebuah dictionary berisi DataFrame untuk setiap ticker yang berhasil dimuat.\n",
    "    \"\"\"\n",
    "    retrieved_data = {}\n",
    "    print(\"\\n--- Memulai Proses Pemuatan Data dari JSON ---\")\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        file_path = os.path.join(json_folder, f\"{ticker}.json\")\n",
    "        \n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"PERINGATAN: File untuk {ticker} tidak ditemukan di '{file_path}'. Melewati...\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Membaca file JSON dan langsung membuatnya menjadi DataFrame\n",
    "            # Pandas sangat baik dalam membaca list of dictionaries\n",
    "            df = pd.read_json(file_path)\n",
    "            \n",
    "            # Melakukan standarisasi kolom dan tipe data\n",
    "            df.rename(columns={'Date': 'Datetime'}, inplace=True) # Menyamakan nama kolom\n",
    "            df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "            df.set_index('Datetime', inplace=True)\n",
    "            \n",
    "            retrieved_data[ticker] = df\n",
    "            print(f\"Data untuk {ticker} berhasil dimuat dan diproses.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Gagal memproses file untuk {ticker}. Kesalahan: {e}\")\n",
    "            \n",
    "    return retrieved_data\n",
    "\n",
    "\n",
    "# --- Bagian 3: Fungsi Terpisah untuk Menyimpan Data ---\n",
    "\n",
    "def save_dataframes(data_dictionary, output_folder='BACKUP_DATASET'):\n",
    "    \"\"\"\n",
    "    Menyimpan setiap DataFrame dalam dictionary ke file CSV dan Excel.\n",
    "\n",
    "    Args:\n",
    "        data_dictionary (dict): Dictionary berisi ticker sebagai key dan DataFrame sebagai value.\n",
    "        output_folder (str): Nama folder tujuan untuk menyimpan file backup.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- Memulai Proses Penyimpanan Data ---\")\n",
    "    if not data_dictionary:\n",
    "        print(\"Tidak ada data untuk disimpan.\")\n",
    "        return\n",
    "\n",
    "    # Membuat folder output jika belum ada\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(f\"Folder '{output_folder}' telah dibuat.\")\n",
    "\n",
    "    for ticker, df in data_dictionary.items():\n",
    "        # Membuat nama file yang aman (mengganti '.' dengan '_')\n",
    "        safe_ticker_name = ticker.replace('.', '_')\n",
    "        \n",
    "        # Mendefinisikan path lengkap untuk file\n",
    "        csv_path = os.path.join(output_folder, f'{safe_ticker_name}.csv')\n",
    "        excel_path = os.path.join(output_folder, f'{safe_ticker_name}.xlsx')\n",
    "\n",
    "        try:\n",
    "            # Menyimpan ke file CSV dan Excel\n",
    "            df.to_csv(csv_path)\n",
    "            df.to_excel(excel_path)\n",
    "            print(f\" -> Data {ticker} berhasil disimpan ke CSV dan Excel.\")\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Gagal menyimpan data untuk {ticker}. Kesalahan: {e}\")\n",
    "\n",
    "\n",
    "tickers = ['ACES.JK', 'ADMR.JK', 'ADRO.JK', 'AKRA.JK', 'AMMN.JK', 'AMRT.JK', 'ANTM.JK',\n",
    "    'ARTO.JK', 'ASII.JK', 'BBCA.JK', 'BBNI.JK', 'BBRI.JK', 'BMRI.JK', 'BRIS.JK',\n",
    "    'BRPT.JK', 'BUKA.JK', 'CPIN.JK', 'EMTK.JK', 'ESSA.JK', 'EXCL.JK', 'GOTO.JK',\n",
    "    'GGRM.JK', 'HRUM.JK', 'ICBP.JK', 'INCO.JK', 'INDF.JK', 'INKP.JK', 'INTP.JK',\n",
    "    'ITMG.JK', 'JPFA.JK', 'JSMR.JK', 'KLBF.JK', 'MAPI.JK', 'MBMA.JK', 'MDKA.JK',\n",
    "    'MEDC.JK', 'PGAS.JK', 'PGEO.JK', 'PTBA.JK', 'SIDO.JK', 'SMGR.JK', 'SRTG.JK',\n",
    "    'TLKM.JK', 'TPIA.JK', 'UNTR.JK', 'UNVR.JK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f759710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langkah 1: Panggil fungsi untuk memuat semua data dari file JSON\n",
    "all_stock_data = load_data_from_json(tickers, json_folder='DATA_JSON')\n",
    "\n",
    "    # Langkah 2: Panggil fungsi terpisah untuk menyimpan data yang sudah dimuat\n",
    "save_dataframes(all_stock_data, output_folder='BACKUP_DATASET')\n",
    "    \n",
    "print(\"\\nProses selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2506b2",
   "metadata": {},
   "source": [
    "## NEWWW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af5eb5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for ACES.JK has been successfully retrieved from MySQL.\n",
      "Data for ADMR.JK has been successfully retrieved from MySQL.\n",
      "Data for ADRO.JK has been successfully retrieved from MySQL.\n",
      "Data for AKRA.JK has been successfully retrieved from MySQL.\n",
      "Data for AMMN.JK has been successfully retrieved from MySQL.\n",
      "Data for AMRT.JK has been successfully retrieved from MySQL.\n",
      "Data for ANTM.JK has been successfully retrieved from MySQL.\n",
      "Data for ARTO.JK has been successfully retrieved from MySQL.\n",
      "Data for ASII.JK has been successfully retrieved from MySQL.\n",
      "Data for BBCA.JK has been successfully retrieved from MySQL.\n",
      "Data for BBNI.JK has been successfully retrieved from MySQL.\n",
      "Data for BBRI.JK has been successfully retrieved from MySQL.\n",
      "Data for BMRI.JK has been successfully retrieved from MySQL.\n",
      "Data for BRIS.JK has been successfully retrieved from MySQL.\n",
      "Data for BRPT.JK has been successfully retrieved from MySQL.\n",
      "Data for BUKA.JK has been successfully retrieved from MySQL.\n",
      "Data for CPIN.JK has been successfully retrieved from MySQL.\n",
      "Data for EMTK.JK has been successfully retrieved from MySQL.\n",
      "Data for ESSA.JK has been successfully retrieved from MySQL.\n",
      "Data for EXCL.JK has been successfully retrieved from MySQL.\n",
      "Data for GOTO.JK has been successfully retrieved from MySQL.\n",
      "Data for GGRM.JK has been successfully retrieved from MySQL.\n",
      "Data for HRUM.JK has been successfully retrieved from MySQL.\n",
      "Data for ICBP.JK has been successfully retrieved from MySQL.\n",
      "Data for INCO.JK has been successfully retrieved from MySQL.\n",
      "Data for INDF.JK has been successfully retrieved from MySQL.\n",
      "Data for INKP.JK has been successfully retrieved from MySQL.\n",
      "Data for INTP.JK has been successfully retrieved from MySQL.\n",
      "Data for ITMG.JK has been successfully retrieved from MySQL.\n",
      "Data for JPFA.JK has been successfully retrieved from MySQL.\n",
      "Data for JSMR.JK has been successfully retrieved from MySQL.\n",
      "Data for KLBF.JK has been successfully retrieved from MySQL.\n",
      "Data for MAPI.JK has been successfully retrieved from MySQL.\n",
      "Data for MBMA.JK has been successfully retrieved from MySQL.\n",
      "Data for MDKA.JK has been successfully retrieved from MySQL.\n",
      "Data for MEDC.JK has been successfully retrieved from MySQL.\n",
      "Data for PGAS.JK has been successfully retrieved from MySQL.\n",
      "Data for PGEO.JK has been successfully retrieved from MySQL.\n",
      "Data for PTBA.JK has been successfully retrieved from MySQL.\n",
      "Data for SIDO.JK has been successfully retrieved from MySQL.\n",
      "Data for SMGR.JK has been successfully retrieved from MySQL.\n",
      "Data for SRTG.JK has been successfully retrieved from MySQL.\n",
      "Data for TLKM.JK has been successfully retrieved from MySQL.\n",
      "Data for TPIA.JK has been successfully retrieved from MySQL.\n",
      "Data for UNTR.JK has been successfully retrieved from MySQL.\n",
      "Data for UNVR.JK has been successfully retrieved from MySQL.\n",
      "Data retrieval and concatenation process from 'data_saham_max_all_mei' completed.\n",
      "                 Open       High        Low      Close      Volume   Ticker\n",
      "Date                                                                       \n",
      "2007-11-06  72.440193  75.396936  65.787522  72.440193  1274430000  ACES.JK\n",
      "2007-11-07  72.440189  76.136117  71.701003  74.657745   349330000  ACES.JK\n",
      "2007-11-08  73.179382  73.918568  70.961825  73.179382    66270000  ACES.JK\n",
      "2007-11-09  70.222649  71.701020  70.222649  70.222649    40075000  ACES.JK\n",
      "2007-11-12  66.526711  70.222639  65.787525  66.526711   113285000  ACES.JK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import json\n",
    "\n",
    "# MySQL connection setup\n",
    "connection = pymysql.connect(\n",
    "    host='localhost',\n",
    "    user='root',\n",
    "    password='',\n",
    "    database='harga_saham'\n",
    ")\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# List of tickers\n",
    "tickers = ['ACES.JK', 'ADMR.JK', 'ADRO.JK', 'AKRA.JK', 'AMMN.JK', 'AMRT.JK', 'ANTM.JK',\n",
    "    'ARTO.JK', 'ASII.JK', 'BBCA.JK', 'BBNI.JK', 'BBRI.JK', 'BMRI.JK', 'BRIS.JK',\n",
    "    'BRPT.JK', 'BUKA.JK', 'CPIN.JK', 'EMTK.JK', 'ESSA.JK', 'EXCL.JK', 'GOTO.JK',\n",
    "    'GGRM.JK', 'HRUM.JK', 'ICBP.JK', 'INCO.JK', 'INDF.JK', 'INKP.JK', 'INTP.JK',\n",
    "    'ITMG.JK', 'JPFA.JK', 'JSMR.JK', 'KLBF.JK', 'MAPI.JK', 'MBMA.JK', 'MDKA.JK',\n",
    "    'MEDC.JK', 'PGAS.JK', 'PGEO.JK', 'PTBA.JK', 'SIDO.JK', 'SMGR.JK', 'SRTG.JK',\n",
    "    'TLKM.JK', 'TPIA.JK', 'UNTR.JK', 'UNVR.JK']\n",
    "\n",
    "# Initialize an empty DataFrame to store all ticker data\n",
    "harga_saham = pd.DataFrame()\n",
    "\n",
    "# Retrieve data from MySQL and store it in harga_saham\n",
    "for ticker in tickers:\n",
    "    sql = f\"SELECT Data FROM data_saham_max_all_mei WHERE Ticker = '{ticker}'\"\n",
    "    cursor.execute(sql)\n",
    "    result = cursor.fetchone()  # Fetch the JSON data\n",
    "    \n",
    "    if result:\n",
    "        # Parse JSON data into a Python list of dictionaries\n",
    "        data_saham_max_all_mei = json.loads(result[0])\n",
    "        \n",
    "        # Convert the list of dictionaries into a DataFrame\n",
    "        df = pd.DataFrame(data_saham_max_all_mei)\n",
    "        \n",
    "        # Ensure 'Date' is in datetime format and set it as the index\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        df.set_index('Date', inplace=True)\n",
    "        \n",
    "        # Add a column for the ticker symbol\n",
    "        df['Ticker'] = ticker\n",
    "        \n",
    "        # Concatenate df to harga_saham (append the new ticker data)\n",
    "        harga_saham = pd.concat([harga_saham, df])\n",
    "        \n",
    "        print(f\"Data for {ticker} has been successfully retrieved from MySQL.\")\n",
    "    else:\n",
    "        print(f\"No data found for {ticker} in MySQL.\")\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "connection.close()\n",
    "\n",
    "print(\"Data retrieval and concatenation process from 'data_saham_max_all_mei' completed.\")\n",
    "print(harga_saham.head())  # Display the first few rows of the combined data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56fd8306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-09-03</th>\n",
       "      <td>306.681173</td>\n",
       "      <td>336.601288</td>\n",
       "      <td>301.694488</td>\n",
       "      <td>336.601288</td>\n",
       "      <td>43162500</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-09-04</th>\n",
       "      <td>344.081325</td>\n",
       "      <td>374.001440</td>\n",
       "      <td>336.601296</td>\n",
       "      <td>341.587982</td>\n",
       "      <td>82850000</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-09-05</th>\n",
       "      <td>341.587895</td>\n",
       "      <td>349.067922</td>\n",
       "      <td>339.094553</td>\n",
       "      <td>344.081238</td>\n",
       "      <td>24055000</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-09-08</th>\n",
       "      <td>344.081321</td>\n",
       "      <td>344.081321</td>\n",
       "      <td>331.614606</td>\n",
       "      <td>339.094635</td>\n",
       "      <td>18007500</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-09-09</th>\n",
       "      <td>339.094622</td>\n",
       "      <td>339.094622</td>\n",
       "      <td>329.121251</td>\n",
       "      <td>331.614594</td>\n",
       "      <td>14075000</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-28</th>\n",
       "      <td>1745.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>1730.000000</td>\n",
       "      <td>25197600</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-02</th>\n",
       "      <td>1730.000000</td>\n",
       "      <td>1765.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>1730.000000</td>\n",
       "      <td>26515500</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03</th>\n",
       "      <td>1720.000000</td>\n",
       "      <td>1765.000000</td>\n",
       "      <td>1685.000000</td>\n",
       "      <td>1690.000000</td>\n",
       "      <td>31456000</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-04</th>\n",
       "      <td>1720.000000</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>1640.000000</td>\n",
       "      <td>1645.000000</td>\n",
       "      <td>31712900</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-05</th>\n",
       "      <td>1655.000000</td>\n",
       "      <td>1655.000000</td>\n",
       "      <td>1605.000000</td>\n",
       "      <td>1625.000000</td>\n",
       "      <td>17144300</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5380 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Volume  \\\n",
       "Date                                                                       \n",
       "2003-09-03   306.681173   336.601288   301.694488   336.601288  43162500   \n",
       "2003-09-04   344.081325   374.001440   336.601296   341.587982  82850000   \n",
       "2003-09-05   341.587895   349.067922   339.094553   344.081238  24055000   \n",
       "2003-09-08   344.081321   344.081321   331.614606   339.094635  18007500   \n",
       "2003-09-09   339.094622   339.094622   329.121251   331.614594  14075000   \n",
       "...                 ...          ...          ...          ...       ...   \n",
       "2025-05-28  1745.000000  1750.000000  1710.000000  1730.000000  25197600   \n",
       "2025-06-02  1730.000000  1765.000000  1710.000000  1730.000000  26515500   \n",
       "2025-06-03  1720.000000  1765.000000  1685.000000  1690.000000  31456000   \n",
       "2025-06-04  1720.000000  1735.000000  1640.000000  1645.000000  31712900   \n",
       "2025-06-05  1655.000000  1655.000000  1605.000000  1625.000000  17144300   \n",
       "\n",
       "             Ticker  \n",
       "Date                 \n",
       "2003-09-03  UNVR.JK  \n",
       "2003-09-04  UNVR.JK  \n",
       "2003-09-05  UNVR.JK  \n",
       "2003-09-08  UNVR.JK  \n",
       "2003-09-09  UNVR.JK  \n",
       "...             ...  \n",
       "2025-05-28  UNVR.JK  \n",
       "2025-06-02  UNVR.JK  \n",
       "2025-06-03  UNVR.JK  \n",
       "2025-06-04  UNVR.JK  \n",
       "2025-06-05  UNVR.JK  \n",
       "\n",
       "[5380 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12d751f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akan mengambil data dari tanggal 2023-07-04 hingga hari ini.\n",
      "--------------------------------------------------\n",
      "Koneksi ke MySQL berhasil.\n",
      "\n",
      "Data untuk ACES.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk ADMR.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk ADRO.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk AKRA.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk AMMN.JK berhasil diambil dan difilter (453 baris).\n",
      "Data untuk AMRT.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk ANTM.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk ARTO.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk ASII.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk BBCA.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk BBNI.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk BBRI.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk BMRI.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk BRIS.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk BRPT.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk BUKA.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk CPIN.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk EMTK.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk ESSA.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk EXCL.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk GOTO.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk GGRM.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk HRUM.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk ICBP.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk INCO.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk INDF.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk INKP.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk INTP.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk ITMG.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk JPFA.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk JSMR.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk KLBF.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk MAPI.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk MBMA.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk MDKA.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk MEDC.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk PGAS.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk PGEO.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk PTBA.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk SIDO.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk SMGR.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk SRTG.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk TLKM.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk TPIA.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk UNTR.JK berhasil diambil dan difilter (455 baris).\n",
      "Data untuk UNVR.JK berhasil diambil dan difilter (455 baris).\n",
      "\n",
      "Koneksi ke MySQL telah ditutup.\n",
      "\n",
      "--- Proses Pengambilan dan Penggabungan Data Selesai ---\n",
      "Total baris data yang terkumpul: 20928\n",
      "\n",
      "Info DataFrame Gabungan:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20928 entries, 2023-07-05 to 2025-06-05\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Open    20928 non-null  float64\n",
      " 1   High    20928 non-null  float64\n",
      " 2   Low     20928 non-null  float64\n",
      " 3   Close   20928 non-null  float64\n",
      " 4   Volume  20928 non-null  int64  \n",
      " 5   Ticker  20928 non-null  object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 1.1+ MB\n",
      "\n",
      "5 Baris Pertama Data Gabungan:\n",
      "                  Open        High         Low       Close     Volume   Ticker\n",
      "Date                                                                          \n",
      "2023-07-05  610.264531  624.680228  600.654066  615.069763  115440700  ACES.JK\n",
      "2023-07-06  619.875008  639.095939  610.264543  629.485474   72533600  ACES.JK\n",
      "2023-07-07  629.485468  715.979654  615.069770  691.953491  391956300  ACES.JK\n",
      "2023-07-10  696.758715  706.369180  677.537785  682.343018  120543400  ACES.JK\n",
      "2023-07-11  682.343018  696.758715  677.537785  682.343018   61117100  ACES.JK\n",
      "\n",
      "5 Baris Terakhir Data Gabungan:\n",
      "              Open    High     Low   Close    Volume   Ticker\n",
      "Date                                                         \n",
      "2025-05-28  1745.0  1750.0  1710.0  1730.0  25197600  UNVR.JK\n",
      "2025-06-02  1730.0  1765.0  1710.0  1730.0  26515500  UNVR.JK\n",
      "2025-06-03  1720.0  1765.0  1685.0  1690.0  31456000  UNVR.JK\n",
      "2025-06-04  1720.0  1735.0  1640.0  1645.0  31712900  UNVR.JK\n",
      "2025-06-05  1655.0  1655.0  1605.0  1625.0  17144300  UNVR.JK\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "import json\n",
    "\n",
    "# --- Persiapan ---\n",
    "# 1. Tentukan tanggal awal (2 tahun dari sekarang)\n",
    "#    Ini dilakukan sekali saja di awal untuk efisiensi.\n",
    "end_date = pd.Timestamp.now()\n",
    "start_date = end_date - pd.DateOffset(years=2)\n",
    "\n",
    "print(f\"Akan mengambil data dari tanggal {start_date.strftime('%Y-%m-%d')} hingga hari ini.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- Koneksi ke MySQL ---\n",
    "try:\n",
    "    connection = pymysql.connect(\n",
    "        host='localhost',\n",
    "        user='root',\n",
    "        password='',\n",
    "        database='harga_saham'\n",
    "    )\n",
    "    cursor = connection.cursor()\n",
    "    print(\"Koneksi ke MySQL berhasil.\\n\")\n",
    "except pymysql.Error as e:\n",
    "    print(f\"Error saat menghubungkan ke MySQL: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- List Ticker ---\n",
    "tickers = ['ACES.JK', 'ADMR.JK', 'ADRO.JK', 'AKRA.JK', 'AMMN.JK', 'AMRT.JK', 'ANTM.JK',\n",
    "    'ARTO.JK', 'ASII.JK', 'BBCA.JK', 'BBNI.JK', 'BBRI.JK', 'BMRI.JK', 'BRIS.JK',\n",
    "    'BRPT.JK', 'BUKA.JK', 'CPIN.JK', 'EMTK.JK', 'ESSA.JK', 'EXCL.JK', 'GOTO.JK',\n",
    "    'GGRM.JK', 'HRUM.JK', 'ICBP.JK', 'INCO.JK', 'INDF.JK', 'INKP.JK', 'INTP.JK',\n",
    "    'ITMG.JK', 'JPFA.JK', 'JSMR.JK', 'KLBF.JK', 'MAPI.JK', 'MBMA.JK', 'MDKA.JK',\n",
    "    'MEDC.JK', 'PGAS.JK', 'PGEO.JK', 'PTBA.JK', 'SIDO.JK', 'SMGR.JK', 'SRTG.JK',\n",
    "    'TLKM.JK', 'TPIA.JK', 'UNTR.JK', 'UNVR.JK']\n",
    "\n",
    "# --- Proses Pengambilan dan Penggabungan Data ---\n",
    "\n",
    "# List untuk menampung semua DataFrame yang sudah difilter (CARA EFISIEN)\n",
    "list_of_dataframes = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    sql = f\"SELECT Data FROM data_saham_max_all_mei WHERE Ticker = '{ticker}'\"\n",
    "    cursor.execute(sql)\n",
    "    result = cursor.fetchone()\n",
    "    \n",
    "    # Pastikan result tidak None dan result[0] (kolom 'Data') punya isi\n",
    "    if result and result[0]:\n",
    "        try:\n",
    "            # Parse JSON menjadi list of dictionaries\n",
    "            data_list = json.loads(result[0])\n",
    "            \n",
    "            # Jika JSON string berisi list kosong '[]', lewati\n",
    "            if not data_list:\n",
    "                print(f\"Data JSON untuk {ticker} kosong. Melewati...\")\n",
    "                continue\n",
    "\n",
    "            # Ubah menjadi DataFrame\n",
    "            df = pd.DataFrame(data_list)\n",
    "            \n",
    "            # Ubah kolom 'Date' menjadi datetime dan jadikan index\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df.set_index('Date', inplace=True)\n",
    "            \n",
    "            # --- FILTER DATA: Ambil data dari 2 tahun terakhir ---\n",
    "            df_filtered = df[df.index >= start_date].copy() # .copy() untuk menghindari SettingWithCopyWarning\n",
    "            \n",
    "            # Jika ada data yang tersisa setelah difilter\n",
    "            if not df_filtered.empty:\n",
    "                # Tambahkan kolom Ticker\n",
    "                df_filtered['Ticker'] = ticker\n",
    "                \n",
    "                # Tambahkan DataFrame yang sudah difilter ke dalam list\n",
    "                list_of_dataframes.append(df_filtered)\n",
    "                \n",
    "                print(f\"Data untuk {ticker} berhasil diambil dan difilter ({len(df_filtered)} baris).\")\n",
    "            else:\n",
    "                print(f\"Tidak ada data untuk {ticker} dalam rentang waktu 2 tahun terakhir.\")\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Gagal mem-parsing JSON untuk ticker {ticker}. Melewati...\")\n",
    "        except Exception as e:\n",
    "            print(f\"Terjadi error saat memproses {ticker}: {e}\")\n",
    "    else:\n",
    "        print(f\"Tidak ada data ditemukan untuk {ticker} di MySQL.\")\n",
    "\n",
    "# --- Tutup Koneksi ---\n",
    "cursor.close()\n",
    "connection.close()\n",
    "print(\"\\nKoneksi ke MySQL telah ditutup.\")\n",
    "\n",
    "# --- Gabungkan Semua DataFrame Menjadi Satu ---\n",
    "if list_of_dataframes:\n",
    "    # Lakukan konkatenasi SATU KALI setelah loop selesai. Jauh lebih cepat!\n",
    "    harga_saham_final = pd.concat(list_of_dataframes)\n",
    "    \n",
    "    print(\"\\n--- Proses Pengambilan dan Penggabungan Data Selesai ---\")\n",
    "    print(f\"Total baris data yang terkumpul: {len(harga_saham_final)}\")\n",
    "    \n",
    "    # Menampilkan informasi dan beberapa baris data\n",
    "    print(\"\\nInfo DataFrame Gabungan:\")\n",
    "    harga_saham_final.info()\n",
    "    \n",
    "    print(\"\\n5 Baris Pertama Data Gabungan:\")\n",
    "    print(harga_saham_final.head())\n",
    "    \n",
    "    print(\"\\n5 Baris Terakhir Data Gabungan:\")\n",
    "    print(harga_saham_final.tail())\n",
    "else:\n",
    "    print(\"\\nTidak ada data yang berhasil dikumpulkan untuk rentang waktu yang ditentukan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c5dc6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-07-05</th>\n",
       "      <td>610.264531</td>\n",
       "      <td>624.680228</td>\n",
       "      <td>600.654066</td>\n",
       "      <td>615.069763</td>\n",
       "      <td>115440700</td>\n",
       "      <td>ACES.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-06</th>\n",
       "      <td>619.875008</td>\n",
       "      <td>639.095939</td>\n",
       "      <td>610.264543</td>\n",
       "      <td>629.485474</td>\n",
       "      <td>72533600</td>\n",
       "      <td>ACES.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-07</th>\n",
       "      <td>629.485468</td>\n",
       "      <td>715.979654</td>\n",
       "      <td>615.069770</td>\n",
       "      <td>691.953491</td>\n",
       "      <td>391956300</td>\n",
       "      <td>ACES.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-10</th>\n",
       "      <td>696.758715</td>\n",
       "      <td>706.369180</td>\n",
       "      <td>677.537785</td>\n",
       "      <td>682.343018</td>\n",
       "      <td>120543400</td>\n",
       "      <td>ACES.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-07-11</th>\n",
       "      <td>682.343018</td>\n",
       "      <td>696.758715</td>\n",
       "      <td>677.537785</td>\n",
       "      <td>682.343018</td>\n",
       "      <td>61117100</td>\n",
       "      <td>ACES.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-05-28</th>\n",
       "      <td>1745.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>1730.000000</td>\n",
       "      <td>25197600</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-02</th>\n",
       "      <td>1730.000000</td>\n",
       "      <td>1765.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>1730.000000</td>\n",
       "      <td>26515500</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-03</th>\n",
       "      <td>1720.000000</td>\n",
       "      <td>1765.000000</td>\n",
       "      <td>1685.000000</td>\n",
       "      <td>1690.000000</td>\n",
       "      <td>31456000</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-04</th>\n",
       "      <td>1720.000000</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>1640.000000</td>\n",
       "      <td>1645.000000</td>\n",
       "      <td>31712900</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-05</th>\n",
       "      <td>1655.000000</td>\n",
       "      <td>1655.000000</td>\n",
       "      <td>1605.000000</td>\n",
       "      <td>1625.000000</td>\n",
       "      <td>17144300</td>\n",
       "      <td>UNVR.JK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20928 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close     Volume  \\\n",
       "Date                                                                        \n",
       "2023-07-05   610.264531   624.680228   600.654066   615.069763  115440700   \n",
       "2023-07-06   619.875008   639.095939   610.264543   629.485474   72533600   \n",
       "2023-07-07   629.485468   715.979654   615.069770   691.953491  391956300   \n",
       "2023-07-10   696.758715   706.369180   677.537785   682.343018  120543400   \n",
       "2023-07-11   682.343018   696.758715   677.537785   682.343018   61117100   \n",
       "...                 ...          ...          ...          ...        ...   \n",
       "2025-05-28  1745.000000  1750.000000  1710.000000  1730.000000   25197600   \n",
       "2025-06-02  1730.000000  1765.000000  1710.000000  1730.000000   26515500   \n",
       "2025-06-03  1720.000000  1765.000000  1685.000000  1690.000000   31456000   \n",
       "2025-06-04  1720.000000  1735.000000  1640.000000  1645.000000   31712900   \n",
       "2025-06-05  1655.000000  1655.000000  1605.000000  1625.000000   17144300   \n",
       "\n",
       "             Ticker  \n",
       "Date                 \n",
       "2023-07-05  ACES.JK  \n",
       "2023-07-06  ACES.JK  \n",
       "2023-07-07  ACES.JK  \n",
       "2023-07-10  ACES.JK  \n",
       "2023-07-11  ACES.JK  \n",
       "...             ...  \n",
       "2025-05-28  UNVR.JK  \n",
       "2025-06-02  UNVR.JK  \n",
       "2025-06-03  UNVR.JK  \n",
       "2025-06-04  UNVR.JK  \n",
       "2025-06-05  UNVR.JK  \n",
       "\n",
       "[20928 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harga_saham_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5455ff1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Menyimpan data ke file CSV di 'BACKUP_DATASET/harga_saham_final.csv'...\n",
      " -> Berhasil.\n",
      "Menyimpan data ke file Excel di 'BACKUP_DATASET/harga_saham_final.xlsx'...\n",
      " -> Berhasil.\n"
     ]
    }
   ],
   "source": [
    "csv_path = 'BACKUP_DATASET/harga_saham_final.csv'\n",
    "excel_path = 'BACKUP_DATASET/harga_saham_final.xlsx'\n",
    "\n",
    "print(f\"\\nMenyimpan data ke file CSV di '{csv_path}'...\")\n",
    "        # index=True agar kolom 'Date' (yang merupakan index) ikut tersimpan\n",
    "harga_saham_final.to_csv(csv_path, index=True)\n",
    "print(\" -> Berhasil.\")\n",
    "        \n",
    "        # 5. Simpan ke Excel\n",
    "print(f\"Menyimpan data ke file Excel di '{excel_path}'...\")\n",
    "        # Catatan: Menyimpan ke Excel bisa memakan waktu lebih lama untuk data besar\n",
    "harga_saham_final.to_excel(excel_path, index=True)\n",
    "print(\" -> Berhasil.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
